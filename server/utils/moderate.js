// utils/moderate.js
import axios from 'axios'
import dotenv from 'dotenv'
dotenv.config()

const HF_API_URL = 'https://api-inference.huggingface.co/models/unitary/toxic-bert'

export async function isToxic(text) {
  console.log('ðŸ“© Incoming content for moderation:', text)

  if (!text || typeof text !== 'string') {
    console.log('âš ï¸ No valid text provided.')
    return false
  }

  try {
    console.log('ðŸŒ Sending request to Hugging Face...')
    const response = await axios.post(
      HF_API_URL,
      { inputs: text },
      {
        headers: {
          Authorization: `Bearer ${process.env.HF_API_KEY}`,
        },
      }
    )

    console.log('âœ… HF API call succeeded.')
    const predictions = response.data?.[0] || []
    console.log('ðŸ“¦ Raw prediction array:', predictions)

    const toxic = predictions.find(i => i.label.toLowerCase() === 'toxicity')
    console.log('ðŸ¤– Extracted verdict:', toxic?.label, toxic?.score)

    const isToxic = toxic?.score > 0.7
    console.log(`ðŸ§  Final decision: ${isToxic ? 'ðŸš« BLOCKED' : 'âœ… ALLOWED'}`)

    return isToxic
  } catch (err) {
    console.error('ðŸ›‘ Hugging Face API failed:', err.message)
    return false
  }
}
